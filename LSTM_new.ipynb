{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取数据\n",
    "import datetime\n",
    "import pandas_datareader.data as pd_data\n",
    "def dataload():\n",
    "    start = datetime.datetime(2000, 1, 1)\n",
    "    end = datetime.datetime(2021, 11, 18)\n",
    "    df = pd_data.DataReader('GOOGL', 'stooq', start, end)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import deque\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#数据预处理\n",
    "def Stock_Price_LSTM_Data_Preprocessing (df, mem_his_days, pre_days):\n",
    "    df.dropna(inplace=True)  # 删除0\n",
    "    df.sort_index(inplace=True)\n",
    "    # inplace(原地)排序，根据之前传进来的日期\n",
    "    df['label'] = df['Close'].shift(-pre_days)  # Close收盘价往上移pre_days个再加到新的label列作为标签\n",
    "    scalar  = StandardScaler()\n",
    "    sca_X = scalar.fit_transform(df.iloc[:, :-1])  #\n",
    "\n",
    "    deq = deque(maxlen=mem_his_days)\n",
    "    # 队列的最大长度为记忆天数\n",
    "\n",
    "    X = []\n",
    "    for i in sca_X:\n",
    "        list(i)\n",
    "        deq.append(list(i))\n",
    "        if len(deq) == mem_his_days:\n",
    "            X.append(list(deq))\n",
    "    # X的shape是(4330,mem_his_days,5);每个样本存的是(mem_his_days，5)的shape\n",
    "    # 每次fori的时候，i是一个5的张量，然后每次X.append5个张量，\n",
    "    # 也就是说mem_his_days天的数据*每天的5个特征\n",
    "    X_latey = X[-pre_days:]\n",
    "    # 少的是(0,men_his_days-1)个，序列未满时的值\n",
    "    X = X[:-pre_days]\n",
    "    # 删掉nan的值。\n",
    "    # 得到纯粹的训练集\n",
    "    y = df['label'][mem_his_days - 1:-pre_days]\n",
    "\n",
    "    X = np.array(X)\n",
    "    # 4330个样本，每个样本有(5天*每天5个特征)\n",
    "    y = np.array(y)\n",
    "\n",
    "    print(len(X))\n",
    "    print(len(y))\n",
    "    print(len(X_latey))\n",
    "    return X, y, X_latey\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "def init_model(the_lstm_layers, the_dense_layers, the_units):\n",
    "    model = Sequential()\n",
    "    # 序列添加\n",
    "    model.add(LSTM(the_units, input_shape=X.shape[1:], activation='relu', return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    for i in range(the_lstm_layers):\n",
    "        model.add(LSTM(the_units, activation='relu', return_sequences=True))\n",
    "        model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(LSTM(the_units, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    for i in range(the_dense_layers):\n",
    "        model.add(Dense(the_units, activation='relu'))\n",
    "        model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mape\"])\n",
    "    # MeanAbsolutePercentageError 平均绝对百分比误差 metrics(度量)\n",
    "    # MeanSquaredError 均方误差\n",
    "    # LSTM，10个神经元\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import os\n",
    "\n",
    "\n",
    "#找一个最好的数据进行预测\n",
    "def model_load():\n",
    "    files = os.listdir('./model')\n",
    "    best_model = load_model(f'./models/{files.sort()[0]}')\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4330\n",
      "4330\n",
      "10\n",
      "WARNING:tensorflow:Layer lstm_73 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_73 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "df = dataload()\n",
    "\n",
    "# model = model()\n",
    "# model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test, y_test))\n",
    "\n",
    "# 多模型训练\n",
    "mem_days = [5, 10, 15]\n",
    "lstm_layers = [1, 2, 3, 4]\n",
    "dense_layers = [1, 2, 3]\n",
    "units = [8, 16, 32]\n",
    "pre_days = 10\n",
    "# 一共训练3*4*3*3个模型\n",
    "for the_mem_days in mem_days:\n",
    "    for the_lstm_layers in lstm_layers:\n",
    "        for the_dense_layers in dense_layers:\n",
    "            for the_units in units:\n",
    "                filepath = './models/{val_mape:.2f}_{epoch:02d}-' + f'mem_{the_mem_days}_lstm_{the_lstm_layers}_dense_{the_dense_layers}_units_{the_units}'\n",
    "                checkpoint_callback = ModelCheckpoint(\n",
    "                    filepath=filepath,\n",
    "                    save_weights_only=False,\n",
    "                    monitor='val_mape',\n",
    "                    mode='min',\n",
    "                    save_best_only=True)\n",
    "                X, y, X_latey = Stock_Price_LSTM_Data_Preprocessing(df, the_mem_days, pre_days)\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size=0.1)\n",
    "                model = init_model(the_lstm_layers, the_dense_layers, the_units)\n",
    "                model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test, y_test), callbacks=[checkpoint_callback])\n",
    "best_model = model_load()\n",
    "print(best_model.summary())\n",
    "print(best_model.evaluate(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4330\n",
      "4330\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "df = dataload()\n",
    "\n",
    "# model = model()\n",
    "# model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test, y_test))\n",
    "\n",
    "# 多模型训练\n",
    "mem_days = [5, 10, 15]\n",
    "\n",
    "pre_days = 10\n",
    "\n",
    "X, y, X_latey = Stock_Price_LSTM_Data_Preprocessing(df, 5, pre_days)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size=0.1)\n",
    "best_model=load_model('./models/4.96_30-mem_5_lstm_2_dense_1_units_16')\n",
    "print(best_model.summary())\n",
    "print(best_model.evaluate(X_test,y_test))\n",
    "pre = best_model.predict(X_test)\n",
    "print(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_time = df.index[-len(y_test)]\n",
    "plt.plot(df_time[0],y_test,color='red',label='price')\n",
    "plt.plot(df_time[0],pre,color='blue',label='pre')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}